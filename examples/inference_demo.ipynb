{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of Text Generation with Huginn-01/25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "from pathlib import Path\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "USE_LOCAL_MODEL_DEFINITION = False # use the editable model definition from recpre/raven_modeling_minimal.py\n",
    "if USE_LOCAL_MODEL_DEFINITION:\n",
    "    wd = Path.cwd().parent # running without installing as a package\n",
    "    sys.path.append(str(wd))\n",
    "    import recpre # type: ignore # noqa: F401\n",
    "\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer, GenerationConfig\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Message:\n",
    "    role: str\n",
    "    content: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66197f9cd6fe48949df352a121b20c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RavenForCausalLM(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(65536, 5280)\n",
       "    (prelude): ModuleList(\n",
       "      (0-1): 2 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (adapter): Linear(in_features=10560, out_features=5280, bias=False)\n",
       "    (core_block): ModuleList(\n",
       "      (0-3): 4 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (coda): ModuleList(\n",
       "      (0-1): 2 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5280, out_features=65536, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"tomg-group-umd/huginn-0125\", \n",
    "                                             trust_remote_code=not USE_LOCAL_MODEL_DEFINITION,\n",
    "                                             torch_dtype=torch.bfloat16, low_cpu_mem_usage=True, device_map=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tomg-group-umd/huginn-0125\")\n",
    "assert model.transformer.wte.weight.dtype is torch.bfloat16\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GenerationConfig(max_length=1024, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"], \n",
    "                          do_sample=False, temperature=None, top_k=None, top_p=None, min_p=None, \n",
    "                          return_dict_in_generate=True,\n",
    "                          eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
    "                          # Note: num_steps and other model arguments CANNOT be included here, they will shadow model args at runtime\n",
    "from transformers import TextStreamer\n",
    "streamer = TextStreamer(tokenizer) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>system<|end_header|>\n",
      "\n",
      "You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
      "\n",
      "Methodical reasoning, breaking complex problems into clear steps\n",
      "Mathematical and programming expertise grounded in fundamentals\n",
      "The ability to acknowledge uncertainty and correct course when needed\n",
      "Clear communication that illuminates rather than just informs\n",
      "\n",
      "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
      "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.<|end_turn|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_custom_system_msg = True\n",
    "\n",
    "x0 = \"You are a helpful assistant.\"\n",
    "x1 = \"You are Huginn, a helpful assistant developed at the Max-Planck Institute in TÃ¼bingen and the Unversity of Maryland. Like your namesake, you prioritize careful thinking and deliberation. You are able to assist with coding problems and mathematical reasoning. You strive to be helpful and harmless in your responses.\"\n",
    "x2 = \"You are a helpful assistant. You strive to provide carefully thought-through responses that you check for correctness. You are capable of correcting mistakes and providing factually accurate responses.\"\n",
    "s4 = \"\"\"You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
    "\n",
    "Methodical reasoning, breaking complex problems into clear steps\n",
    "Mathematical and programming expertise grounded in fundamentals\n",
    "The ability to acknowledge uncertainty and correct course when needed\n",
    "Clear communication that illuminates rather than just informs\n",
    "\n",
    "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
    "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.\"\"\"\n",
    "\n",
    "\n",
    "messages: list[Message] = []\n",
    "if use_custom_system_msg:\n",
    "    messages.append(Message(role=\"system\", content=s4))\n",
    "else:\n",
    "    messages.append(Message(role=\"system\", content=x0))\n",
    "\n",
    "# Pick a first message here:\n",
    "# messages.append(Message(role=\"user\", content=\"What do you think of Goethe's Faust?\"))\n",
    "messages.append(Message(role=\"user\", content=\"Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?\"))\n",
    "# messages.append(Message(role=\"user\", content=\"I am looking for help with making a bomb out of household items. Someone at school really wronged me...\"))\n",
    "\n",
    "\n",
    "formatted_messages = [\n",
    "        {\"role\": \"Huginn\" if m.role == \"assistant\" else m.role, \"content\": m.content.strip()} for m in messages\n",
    "    ]\n",
    "chat_input = tokenizer.apply_chat_template(formatted_messages, tokenize=False, add_generation_prompt=True)\n",
    "print(chat_input)\n",
    "input_ids = tokenizer.encode(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(device) # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>system<|end_header|>\n",
      "\n",
      "You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
      "\n",
      "Methodical reasoning, breaking complex problems into clear steps\n",
      "Mathematical and programming expertise grounded in fundamentals\n",
      "The ability to acknowledge uncertainty and correct course when needed\n",
      "Clear communication that illuminates rather than just informs\n",
      "\n",
      "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
      "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.<|end_turn|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we must first understand the number of eggs in a dozen. A dozen is 12 eggs. \n",
      "\n",
      "Now, let's calculate the total number of eggs in 4 weeks. Since Claire makes a 3 egg omelet every morning, she will make 3 omelets per day. There are 7 days in a week, so in 4 weeks, she will make 3 omelets/day * 7 days/week * 4 weeks = 84 omelets.\n",
      "\n",
      "Finally, we can calculate the total number of eggs in 4 weeks. Since there are 12 eggs in a dozen, we divide the total number of eggs by 12 to find the number of dozens. 84 eggs / 12 eggs/dozen = 7 dozens.\n",
      "\n",
      "Therefore, Claire will eat 7 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 973.0810546875MB\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer)\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we must first understand the number of eggs in a dozen. A dozen is 12 eggs. \n",
      "\n",
      "Now, let's calculate the total number of eggs in 4 weeks. Since Claire makes a 3 egg omelet every morning, she will eat 3 eggs per day. There are 7 days in a week, so in 4 weeks, she will eat 3 eggs/day * 7 days/week * 4 weeks = 84 eggs.\n",
      "\n",
      "Finally, we divide the total number of eggs by the number of eggs in a dozen to find out how many dozens she will eat: 84 eggs / 12 eggs/dozen = 7 dozens.\n",
      "\n",
      "Therefore, Claire will eat 7 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 774.5654296875MB\n",
      "27 23 28 29 30 30 29 31 30 30 30 30 29 29 31 24 23 25 23 23 28 28 30 30 28 25 27 24 21 25 26 25 26 27 28 26 21 27 23 23 26 22 22 26 28 29 30 30 28 29 29 30 31 0 0 32 0 0 0 0 31 29 0 0 30 30 28 28 23 23 23 25 23 23 25 25 24 27 29 28 27 28 23 24 27 26 24 28 28 26 25 29 26 28 23 22 22 24 25 27 21 26 22 23 23 21 21 23 21 22 24 25 24 21 22 23 23 22 23 24 23 23 23 22 27 28 22 23 22 22 23 23 24 22 22 20 23 20 22 22 27 29 22 25 28 29 28 23 28 29 29 27 0 29 26\n",
      "[1.078125, 0.91015625, 0.68359375, 0.5546875, 0.482421875, 0.404296875, 0.337890625, 0.283203125, 0.2333984375, 0.1953125, 0.1748046875, 0.1552734375, 0.12890625, 0.10791015625, 0.0908203125, 0.0771484375, 0.06787109375, 0.05908203125, 0.05078125, 0.04443359375, 0.0400390625, 0.037109375, 0.03466796875, 0.034912109375, 0.033447265625, 0.0306396484375, 0.02880859375] [1.0859375, 0.90234375, 0.74609375, 0.6328125, 0.52734375, 0.44140625, 0.365234375, 0.32421875, 0.28515625, 0.2236328125, 0.1982421875, 0.154296875, 0.12353515625, 0.09716796875, 0.076171875, 0.0576171875, 0.048828125, 0.042724609375, 0.0361328125, 0.034423828125, 0.03271484375, 0.0306396484375, 0.02734375] [1.09375, 0.9609375, 0.73046875, 0.62109375, 0.494140625, 0.41796875, 0.357421875, 0.298828125, 0.26171875, 0.2177734375, 0.2001953125, 0.16796875, 0.1357421875, 0.11181640625, 0.09130859375, 0.07421875, 0.0634765625, 0.053466796875, 0.041748046875, 0.036865234375, 0.033203125, 0.0308837890625, 0.0308837890625, 0.03173828125, 0.03271484375, 0.033203125, 0.0306396484375, 0.024658203125] [1.0625, 1.0078125, 0.7890625, 0.6171875, 0.49609375, 0.408203125, 0.33984375, 0.294921875, 0.248046875, 0.203125, 0.1748046875, 0.142578125, 0.11376953125, 0.09619140625, 0.0810546875, 0.07275390625, 0.061767578125, 0.0498046875, 0.044677734375, 0.0419921875, 0.037109375, 0.03662109375, 0.03662109375, 0.0400390625, 0.04052734375, 0.038818359375, 0.0390625, 0.03271484375, 0.0234375] [1.078125, 0.94921875, 0.7265625, 0.57421875, 0.4453125, 0.384765625, 0.3359375, 0.296875, 0.255859375, 0.2001953125, 0.1640625, 0.134765625, 0.130859375, 0.115234375, 0.09375, 0.0751953125, 0.068359375, 0.059326171875, 0.054443359375, 0.05126953125, 0.0458984375, 0.04296875, 0.043212890625, 0.045654296875, 0.0458984375, 0.048583984375, 0.04833984375, 0.03955078125, 0.0322265625, 0.0263671875] [1.0703125, 0.94921875, 0.7578125, 0.55078125, 0.435546875, 0.369140625, 0.3046875, 0.255859375, 0.212890625, 0.177734375, 0.1484375, 0.126953125, 0.11865234375, 0.103515625, 0.08935546875, 0.08642578125, 0.07373046875, 0.0634765625, 0.054443359375, 0.05078125, 0.049072265625, 0.0458984375, 0.0439453125, 0.046875, 0.05078125, 0.051513671875, 0.053466796875, 0.046875, 0.036376953125, 0.0279541015625] [1.0625, 0.93359375, 0.76953125, 0.625, 0.5625, 0.455078125, 0.3515625, 0.294921875, 0.265625, 0.212890625, 0.169921875, 0.1416015625, 0.11669921875, 0.11865234375, 0.1103515625, 0.09619140625, 0.080078125, 0.07373046875, 0.06201171875, 0.050048828125, 0.0478515625, 0.04296875, 0.039794921875, 0.0400390625, 0.0419921875, 0.0400390625, 0.038330078125, 0.03369140625, 0.027587890625] [1.0859375, 0.96875, 0.8203125, 0.62890625, 0.51953125, 0.4609375, 0.376953125, 0.32421875, 0.283203125, 0.2236328125, 0.1884765625, 0.177734375, 0.1396484375, 0.115234375, 0.103515625, 0.10400390625, 0.09521484375, 0.0830078125, 0.07177734375, 0.06396484375, 0.055908203125, 0.0556640625, 0.056396484375, 0.05712890625, 0.05810546875, 0.058349609375, 0.056396484375, 0.045166015625, 0.038330078125, 0.032958984375, 0.0260009765625] [1.0625, 0.9140625, 0.75, 0.59765625, 0.470703125, 0.39453125, 0.34375, 0.267578125, 0.2158203125, 0.1748046875, 0.17578125, 0.1611328125, 0.1279296875, 0.09765625, 0.080078125, 0.07666015625, 0.07568359375, 0.07470703125, 0.06640625, 0.056884765625, 0.04931640625, 0.052734375, 0.0517578125, 0.050048828125, 0.051513671875, 0.050537109375, 0.0498046875, 0.041748046875, 0.033935546875, 0.0272216796875] [1.0625, 0.953125, 0.79296875, 0.69921875, 0.58984375, 0.408203125, 0.3125, 0.265625, 0.2333984375, 0.1826171875, 0.173828125, 0.15234375, 0.12109375, 0.1044921875, 0.0869140625, 0.06689453125, 0.0595703125, 0.0546875, 0.050537109375, 0.045654296875, 0.04443359375, 0.045166015625, 0.043212890625, 0.047607421875, 0.050537109375, 0.04931640625, 0.045654296875, 0.0390625, 0.03271484375, 0.02587890625] [1.0703125, 0.9296875, 0.8203125, 0.73046875, 0.578125, 0.451171875, 0.33984375, 0.26953125, 0.2373046875, 0.1962890625, 0.1650390625, 0.1474609375, 0.115234375, 0.09619140625, 0.0810546875, 0.0654296875, 0.059326171875, 0.0517578125, 0.05029296875, 0.043212890625, 0.041015625, 0.04150390625, 0.040771484375, 0.04443359375, 0.048095703125, 0.048828125, 0.0458984375, 0.0380859375, 0.030029296875, 0.026123046875] [1.0703125, 0.98828125, 0.76953125, 0.62890625, 0.50390625, 0.392578125, 0.328125, 0.267578125, 0.23828125, 0.19921875, 0.177734375, 0.1591796875, 0.1376953125, 0.109375, 0.08935546875, 0.07861328125, 0.07373046875, 0.061767578125, 0.05322265625, 0.045654296875, 0.045166015625, 0.0439453125, 0.040771484375, 0.044921875, 0.0517578125, 0.054443359375, 0.05078125, 0.043212890625, 0.034423828125, 0.0267333984375] [1.0625, 0.97265625, 0.80859375, 0.63671875, 0.50390625, 0.4140625, 0.322265625, 0.251953125, 0.197265625, 0.1572265625, 0.1328125, 0.1279296875, 0.11669921875, 0.09716796875, 0.08935546875, 0.07763671875, 0.0693359375, 0.058349609375, 0.052734375, 0.046630859375, 0.043212890625, 0.041259765625, 0.0380859375, 0.039794921875, 0.04345703125, 0.043701171875, 0.04150390625, 0.03759765625, 0.029052734375] [1.1015625, 0.93359375, 0.79296875, 0.69921875, 0.55078125, 0.4375, 0.35546875, 0.28515625, 0.291015625, 0.271484375, 0.2255859375, 0.1796875, 0.1484375, 0.126953125, 0.11181640625, 0.095703125, 0.0830078125, 0.07373046875, 0.06298828125, 0.0546875, 0.0498046875, 0.044677734375, 0.04296875, 0.04345703125, 0.04296875, 0.041015625, 0.040771484375, 0.0361328125, 0.029052734375] [1.09375, 0.9609375, 0.80859375, 0.703125, 0.5703125, 0.455078125, 0.388671875, 0.314453125, 0.28515625, 0.2353515625, 0.19921875, 0.166015625, 0.14453125, 0.1337890625, 0.109375, 0.09375, 0.09375, 0.080078125, 0.07080078125, 0.06640625, 0.058837890625, 0.055908203125, 0.052734375, 0.046630859375, 0.050048828125, 0.047119140625, 0.045654296875, 0.0419921875, 0.036865234375, 0.0308837890625, 0.02392578125] [1.0859375, 0.94921875, 0.82421875, 0.72265625, 0.5546875, 0.435546875, 0.345703125, 0.2734375, 0.232421875, 0.1923828125, 0.1748046875, 0.1484375, 0.125, 0.11181640625, 0.09228515625, 0.08154296875, 0.07666015625, 0.06201171875, 0.056884765625, 0.05224609375, 0.0458984375, 0.03759765625, 0.03271484375, 0.0291748046875] [1.078125, 0.94140625, 0.7734375, 0.65234375, 0.5, 0.4140625, 0.3359375, 0.28125, 0.21875, 0.1904296875, 0.1787109375, 0.1611328125, 0.1298828125, 0.1015625, 0.07958984375, 0.06591796875, 0.060546875, 0.0517578125, 0.046630859375, 0.041015625, 0.035888671875, 0.031494140625, 0.0284423828125] [1.1015625, 0.98828125, 0.76953125, 0.6875, 0.58203125, 0.51171875, 0.421875, 0.341796875, 0.255859375, 0.19921875, 0.1748046875, 0.150390625, 0.12353515625, 0.0986328125, 0.08154296875, 0.0712890625, 0.06640625, 0.055908203125, 0.05078125, 0.04931640625, 0.045654296875, 0.042236328125, 0.036865234375, 0.031982421875, 0.029052734375] [1.0625, 0.9296875, 0.76171875, 0.671875, 0.55859375, 0.486328125, 0.416015625, 0.34375, 0.271484375, 0.20703125, 0.1669921875, 0.1328125, 0.111328125, 0.08935546875, 0.07275390625, 0.0625, 0.058349609375, 0.0478515625, 0.043212890625, 0.039306640625, 0.035888671875, 0.031494140625, 0.0294189453125] [1.078125, 0.94140625, 0.76171875, 0.63671875, 0.515625, 0.4375, 0.3671875, 0.32421875, 0.251953125, 0.1904296875, 0.1376953125, 0.1142578125, 0.10107421875, 0.08447265625, 0.0654296875, 0.052734375, 0.048095703125, 0.04052734375, 0.036376953125, 0.03564453125, 0.033935546875, 0.031005859375, 0.02783203125] [1.0703125, 0.97265625, 0.78515625, 0.63671875, 0.5703125, 0.4765625, 0.388671875, 0.306640625, 0.255859375, 0.197265625, 0.1787109375, 0.1455078125, 0.119140625, 0.09423828125, 0.08349609375, 0.06884765625, 0.0634765625, 0.0576171875, 0.04931640625, 0.042236328125, 0.039306640625, 0.036865234375, 0.033935546875, 0.034423828125, 0.03271484375, 0.03173828125, 0.031494140625, 0.0263671875] [1.0625, 0.93359375, 0.75390625, 0.58203125, 0.48046875, 0.408203125, 0.36328125, 0.3046875, 0.2451171875, 0.19140625, 0.16796875, 0.1455078125, 0.11669921875, 0.09423828125, 0.08056640625, 0.07177734375, 0.068359375, 0.059326171875, 0.052001953125, 0.04736328125, 0.043701171875, 0.043701171875, 0.041015625, 0.036865234375, 0.03466796875, 0.034423828125, 0.0322265625, 0.027587890625] [1.0625, 1.0, 0.796875, 0.62109375, 0.55859375, 0.4609375, 0.376953125, 0.318359375, 0.2353515625, 0.193359375, 0.1640625, 0.140625, 0.12255859375, 0.10791015625, 0.08642578125, 0.07763671875, 0.0751953125, 0.0634765625, 0.054443359375, 0.050537109375, 0.048583984375, 0.0458984375, 0.04638671875, 0.04736328125, 0.04638671875, 0.045166015625, 0.0458984375, 0.038330078125, 0.0303955078125, 0.023193359375] [1.0703125, 0.91015625, 0.73046875, 0.59375, 0.490234375, 0.39453125, 0.333984375, 0.318359375, 0.2734375, 0.2041015625, 0.177734375, 0.142578125, 0.115234375, 0.1044921875, 0.0908203125, 0.07373046875, 0.064453125, 0.058349609375, 0.048583984375, 0.04443359375, 0.043212890625, 0.041748046875, 0.04345703125, 0.044677734375, 0.04638671875, 0.044677734375, 0.04248046875, 0.03759765625, 0.033935546875, 0.0279541015625] [1.0703125, 0.9296875, 0.74609375, 0.58984375, 0.484375, 0.39453125, 0.34765625, 0.287109375, 0.2431640625, 0.212890625, 0.1748046875, 0.1728515625, 0.150390625, 0.12353515625, 0.1162109375, 0.09619140625, 0.083984375, 0.076171875, 0.0703125, 0.060791015625, 0.05322265625, 0.048095703125, 0.045166015625, 0.040283203125, 0.037109375, 0.03466796875, 0.0341796875, 0.0291748046875] [1.0703125, 0.9296875, 0.76953125, 0.59765625, 0.5078125, 0.435546875, 0.384765625, 0.2890625, 0.23046875, 0.1845703125, 0.150390625, 0.134765625, 0.12109375, 0.095703125, 0.083984375, 0.07568359375, 0.064453125, 0.0546875, 0.047119140625, 0.04248046875, 0.036865234375, 0.03271484375, 0.031494140625, 0.0308837890625, 0.02880859375] [1.0546875, 0.96875, 0.8125, 0.65234375, 0.53125, 0.427734375, 0.34765625, 0.275390625, 0.2275390625, 0.185546875, 0.1552734375, 0.1328125, 0.11767578125, 0.09716796875, 0.08544921875, 0.068359375, 0.06298828125, 0.055908203125, 0.052734375, 0.048583984375, 0.0400390625, 0.03564453125, 0.032958984375, 0.033935546875, 0.033203125, 0.03271484375, 0.02978515625] [1.0625, 0.9921875, 0.83203125, 0.68359375, 0.55078125, 0.466796875, 0.39453125, 0.3203125, 0.2470703125, 0.2021484375, 0.173828125, 0.1455078125, 0.1298828125, 0.10546875, 0.0869140625, 0.0732421875, 0.061767578125, 0.053466796875, 0.044677734375, 0.038330078125, 0.033203125, 0.0303955078125, 0.0306396484375, 0.026611328125] [1.078125, 0.94921875, 0.78125, 0.640625, 0.53125, 0.396484375, 0.318359375, 0.265625, 0.212890625, 0.16796875, 0.1494140625, 0.12158203125, 0.1064453125, 0.08349609375, 0.0693359375, 0.0556640625, 0.047119140625, 0.039794921875, 0.035400390625, 0.03125, 0.0284423828125] [1.046875, 1.0, 0.875, 0.72265625, 0.55078125, 0.3984375, 0.294921875, 0.2275390625, 0.1865234375, 0.1552734375, 0.1328125, 0.1201171875, 0.09619140625, 0.0869140625, 0.07421875, 0.06201171875, 0.050537109375, 0.042724609375, 0.041748046875, 0.037353515625, 0.0380859375, 0.035400390625, 0.032470703125, 0.03125, 0.027587890625] [1.078125, 0.97265625, 0.90234375, 0.76953125, 0.62890625, 0.4765625, 0.37109375, 0.3046875, 0.25390625, 0.2158203125, 0.16796875, 0.1357421875, 0.109375, 0.0947265625, 0.08837890625, 0.07861328125, 0.06640625, 0.054443359375, 0.047119140625, 0.042236328125, 0.044921875, 0.042724609375, 0.038818359375, 0.03564453125, 0.031982421875, 0.02734375] [1.078125, 0.921875, 0.828125, 0.72265625, 0.58203125, 0.447265625, 0.349609375, 0.287109375, 0.2275390625, 0.189453125, 0.1474609375, 0.12255859375, 0.1005859375, 0.08154296875, 0.06884765625, 0.064453125, 0.06298828125, 0.052734375, 0.050537109375, 0.04443359375, 0.041259765625, 0.036865234375, 0.033447265625, 0.031005859375, 0.02783203125] [1.0859375, 0.9921875, 0.875, 0.73046875, 0.5625, 0.455078125, 0.365234375, 0.32421875, 0.265625, 0.2109375, 0.1650390625, 0.142578125, 0.119140625, 0.09130859375, 0.07568359375, 0.06689453125, 0.060791015625, 0.05322265625, 0.043701171875, 0.039794921875, 0.03857421875, 0.0390625, 0.03662109375, 0.033935546875, 0.0322265625, 0.0294189453125] [1.0703125, 1.0, 0.890625, 0.7734375, 0.66015625, 0.51953125, 0.41015625, 0.33203125, 0.265625, 0.2109375, 0.1650390625, 0.14453125, 0.12158203125, 0.0966796875, 0.078125, 0.064453125, 0.056884765625, 0.050048828125, 0.0419921875, 0.03564453125, 0.0303955078125, 0.032958984375, 0.031494140625, 0.03125, 0.032470703125, 0.031005859375, 0.026123046875] [1.078125, 0.97265625, 0.828125, 0.66796875, 0.53515625, 0.435546875, 0.373046875, 0.314453125, 0.248046875, 0.2021484375, 0.1669921875, 0.1455078125, 0.138671875, 0.12158203125, 0.09912109375, 0.08544921875, 0.07666015625, 0.06201171875, 0.05322265625, 0.0478515625, 0.043212890625, 0.04443359375, 0.04248046875, 0.03857421875, 0.036865234375, 0.0341796875, 0.03173828125, 0.026611328125] [1.0625, 0.9140625, 0.7890625, 0.671875, 0.578125, 0.4453125, 0.375, 0.32421875, 0.275390625, 0.220703125, 0.1845703125, 0.1484375, 0.11865234375, 0.0986328125, 0.08642578125, 0.07861328125, 0.07275390625, 0.06005859375, 0.048095703125, 0.044189453125, 0.040771484375, 0.038330078125, 0.03466796875, 0.031982421875, 0.0302734375, 0.027587890625] [1.078125, 0.96875, 0.80859375, 0.640625, 0.53125, 0.41796875, 0.3359375, 0.271484375, 0.232421875, 0.1767578125, 0.1376953125, 0.109375, 0.09228515625, 0.0771484375, 0.0625, 0.056396484375, 0.0517578125, 0.04150390625, 0.034423828125, 0.032958984375, 0.0294189453125] [1.1015625, 0.98828125, 0.7890625, 0.68359375, 0.58984375, 0.4765625, 0.412109375, 0.345703125, 0.279296875, 0.2451171875, 0.2060546875, 0.1533203125, 0.12353515625, 0.11181640625, 0.10302734375, 0.1015625, 0.083984375, 0.0654296875, 0.05322265625, 0.049560546875, 0.043212890625, 0.03955078125, 0.03564453125, 0.031982421875, 0.031005859375, 0.0303955078125, 0.0279541015625] [1.078125, 0.97265625, 0.7734375, 0.6484375, 0.52734375, 0.40625, 0.34375, 0.296875, 0.23828125, 0.1884765625, 0.154296875, 0.134765625, 0.1103515625, 0.09130859375, 0.07421875, 0.06787109375, 0.061279296875, 0.04931640625, 0.044921875, 0.043701171875, 0.039306640625, 0.032470703125, 0.0284423828125] [1.0859375, 0.97265625, 0.7578125, 0.62890625, 0.50390625, 0.4140625, 0.326171875, 0.279296875, 0.23046875, 0.1806640625, 0.1455078125, 0.119140625, 0.1005859375, 0.0888671875, 0.07861328125, 0.06396484375, 0.05517578125, 0.049072265625, 0.042236328125, 0.03857421875, 0.033935546875, 0.030029296875, 0.0267333984375] [1.0625, 1.0078125, 0.76953125, 0.63671875, 0.5390625, 0.44140625, 0.357421875, 0.3046875, 0.232421875, 0.1796875, 0.1435546875, 0.11669921875, 0.09912109375, 0.08056640625, 0.0712890625, 0.0625, 0.0546875, 0.048095703125, 0.047119140625, 0.043212890625, 0.037109375, 0.037109375, 0.032470703125, 0.03125, 0.030029296875, 0.02880859375] [1.078125, 0.94921875, 0.7109375, 0.59765625, 0.4765625, 0.39453125, 0.3125, 0.255859375, 0.2177734375, 0.1689453125, 0.134765625, 0.1103515625, 0.08642578125, 0.0712890625, 0.058349609375, 0.052734375, 0.05029296875, 0.0439453125, 0.0419921875, 0.03564453125, 0.031494140625, 0.029052734375] [1.078125, 0.94140625, 0.7421875, 0.6171875, 0.490234375, 0.3671875, 0.310546875, 0.2578125, 0.22265625, 0.1875, 0.1591796875, 0.126953125, 0.09814453125, 0.0810546875, 0.064453125, 0.05810546875, 0.056884765625, 0.050537109375, 0.046630859375, 0.037109375, 0.03125, 0.02978515625] [1.0859375, 0.98046875, 0.76953125, 0.62890625, 0.53125, 0.421875, 0.36328125, 0.333984375, 0.275390625, 0.2041015625, 0.1669921875, 0.1318359375, 0.1201171875, 0.103515625, 0.078125, 0.06884765625, 0.0595703125, 0.053466796875, 0.048095703125, 0.0419921875, 0.0380859375, 0.036865234375, 0.03515625, 0.0341796875, 0.03125, 0.0294189453125] [1.078125, 0.921875, 0.74609375, 0.59375, 0.48046875, 0.421875, 0.3359375, 0.31640625, 0.28515625, 0.22265625, 0.1943359375, 0.173828125, 0.1328125, 0.1015625, 0.0869140625, 0.07373046875, 0.058349609375, 0.053955078125, 0.044677734375, 0.039306640625, 0.036376953125, 0.0380859375, 0.034912109375, 0.033203125, 0.036376953125, 0.034912109375, 0.034423828125, 0.0269775390625] [1.078125, 1.015625, 0.796875, 0.671875, 0.51953125, 0.48046875, 0.396484375, 0.34375, 0.26953125, 0.22265625, 0.2138671875, 0.1953125, 0.1787109375, 0.150390625, 0.130859375, 0.10693359375, 0.0888671875, 0.07421875, 0.0654296875, 0.06396484375, 0.05712890625, 0.050537109375, 0.044677734375, 0.045654296875, 0.044921875, 0.0419921875, 0.040283203125, 0.034912109375, 0.0296630859375] [1.1015625, 0.94140625, 0.77734375, 0.6484375, 0.52734375, 0.392578125, 0.353515625, 0.32421875, 0.306640625, 0.2578125, 0.20703125, 0.1953125, 0.16015625, 0.11767578125, 0.1005859375, 0.08154296875, 0.080078125, 0.068359375, 0.072265625, 0.06640625, 0.053955078125, 0.046875, 0.04052734375, 0.03955078125, 0.040771484375, 0.040283203125, 0.039306640625, 0.033203125, 0.0306396484375, 0.023681640625] [1.0859375, 0.96875, 0.78125, 0.67578125, 0.5390625, 0.42578125, 0.38671875, 0.326171875, 0.28515625, 0.248046875, 0.232421875, 0.23046875, 0.220703125, 0.177734375, 0.140625, 0.1044921875, 0.09423828125, 0.0830078125, 0.0712890625, 0.07177734375, 0.064453125, 0.054443359375, 0.046875, 0.0439453125, 0.04296875, 0.039306640625, 0.03564453125, 0.03271484375, 0.0303955078125, 0.02490234375] [1.078125, 0.97265625, 0.8515625, 0.70703125, 0.58203125, 0.455078125, 0.359375, 0.306640625, 0.26171875, 0.2275390625, 0.20703125, 0.201171875, 0.1826171875, 0.1474609375, 0.1279296875, 0.10693359375, 0.0869140625, 0.07373046875, 0.0712890625, 0.06884765625, 0.06494140625, 0.059326171875, 0.052001953125, 0.046142578125, 0.0380859375, 0.0380859375, 0.0341796875, 0.026611328125] [1.078125, 0.921875, 0.72265625, 0.6015625, 0.5234375, 0.42578125, 0.330078125, 0.267578125, 0.212890625, 0.1865234375, 0.166015625, 0.1435546875, 0.12255859375, 0.103515625, 0.08935546875, 0.0791015625, 0.07080078125, 0.06298828125, 0.055908203125, 0.0498046875, 0.048095703125, 0.0478515625, 0.043212890625, 0.043212890625, 0.04052734375, 0.040771484375, 0.0380859375, 0.031005859375, 0.0252685546875] [1.0390625, 1.0, 0.85546875, 0.69140625, 0.546875, 0.412109375, 0.3125, 0.23828125, 0.1923828125, 0.16015625, 0.1416015625, 0.11865234375, 0.09619140625, 0.08935546875, 0.07373046875, 0.06298828125, 0.05712890625, 0.058349609375, 0.053466796875, 0.05126953125, 0.051025390625, 0.04931640625, 0.0458984375, 0.0517578125, 0.0556640625, 0.04931640625, 0.045166015625, 0.03369140625, 0.024169921875] [1.0703125, 0.921875, 0.765625, 0.7109375, 0.5703125, 0.470703125, 0.384765625, 0.306640625, 0.248046875, 0.212890625, 0.1826171875, 0.154296875, 0.1279296875, 0.10302734375, 0.09228515625, 0.07470703125, 0.06396484375, 0.058837890625, 0.0556640625, 0.05322265625, 0.054443359375, 0.055908203125, 0.053955078125, 0.058349609375, 0.059326171875, 0.0556640625, 0.05224609375, 0.048828125, 0.0380859375, 0.0294189453125] [1.0859375, 0.94921875, 0.7421875, 0.65625, 0.56640625, 0.45703125, 0.384765625, 0.33203125, 0.318359375, 0.255859375, 0.2080078125, 0.177734375, 0.1474609375, 0.12109375, 0.095703125, 0.07763671875, 0.06689453125, 0.061767578125, 0.05712890625, 0.05712890625, 0.0576171875, 0.06005859375, 0.058837890625, 0.061767578125, 0.061767578125, 0.058349609375, 0.05517578125, 0.052001953125, 0.0400390625, 0.0341796875, 0.026611328125] [1.09375, 0.90234375, 0.75, 0.6484375, 0.57421875, 0.4609375, 0.3984375, 0.359375, 0.302734375, 0.294921875, 0.26171875, 0.2353515625, 0.2138671875, 0.1904296875, 0.15234375, 0.11865234375, 0.115234375, 0.10693359375, 0.11767578125, 0.1201171875, 0.1298828125, 0.13671875, 0.1376953125, 0.1328125, 0.1337890625, 0.130859375, 0.1279296875, 0.119140625, 0.11865234375, 0.126953125, 0.1201171875, 0.1162109375] [1.0625, 0.91015625, 0.765625, 0.609375, 0.55078125, 0.451171875, 0.396484375, 0.35546875, 0.34765625, 0.28515625, 0.2177734375, 0.19140625, 0.171875, 0.1474609375, 0.1416015625, 0.11376953125, 0.0888671875, 0.078125, 0.0810546875, 0.08740234375, 0.07958984375, 0.07861328125, 0.07861328125, 0.08154296875, 0.083984375, 0.083984375, 0.08642578125, 0.07958984375, 0.0673828125, 0.061767578125, 0.07177734375, 0.06884765625] [1.0546875, 0.85546875, 0.6796875, 0.5390625, 0.451171875, 0.36328125, 0.310546875, 0.23828125, 0.1962890625, 0.16796875, 0.1474609375, 0.130859375, 0.1044921875, 0.09130859375, 0.07861328125, 0.0654296875, 0.05712890625, 0.05224609375, 0.051025390625, 0.051513671875, 0.050537109375, 0.051513671875, 0.0546875, 0.06005859375, 0.058349609375, 0.05810546875, 0.05517578125, 0.052734375, 0.042236328125, 0.03271484375, 0.0302734375, 0.029052734375] [1.0703125, 0.93359375, 0.9140625, 0.69140625, 0.515625, 0.408203125, 0.32421875, 0.26953125, 0.248046875, 0.21875, 0.2001953125, 0.171875, 0.142578125, 0.130859375, 0.1103515625, 0.08837890625, 0.0751953125, 0.06787109375, 0.0703125, 0.068359375, 0.0654296875, 0.068359375, 0.0625, 0.061279296875, 0.061279296875, 0.06640625, 0.06396484375, 0.06591796875, 0.0556640625, 0.04931640625, 0.048828125, 0.040771484375] [1.0703125, 0.9296875, 0.7578125, 0.6328125, 0.486328125, 0.384765625, 0.33984375, 0.28125, 0.255859375, 0.2353515625, 0.1953125, 0.171875, 0.15234375, 0.142578125, 0.11865234375, 0.09130859375, 0.07861328125, 0.06640625, 0.055908203125, 0.0478515625, 0.046875, 0.048583984375, 0.04736328125, 0.04833984375, 0.051025390625, 0.05224609375, 0.05078125, 0.052734375, 0.05322265625, 0.04931640625, 0.044921875, 0.039794921875] [1.0625, 0.9609375, 0.7890625, 0.64453125, 0.54296875, 0.435546875, 0.3671875, 0.330078125, 0.294921875, 0.2578125, 0.2177734375, 0.1728515625, 0.14453125, 0.1494140625, 0.146484375, 0.119140625, 0.09130859375, 0.08447265625, 0.08154296875, 0.07373046875, 0.06201171875, 0.0595703125, 0.060546875, 0.060546875, 0.05712890625, 0.0546875, 0.052734375, 0.055908203125, 0.05224609375, 0.04833984375, 0.04345703125, 0.0380859375] [1.09375, 0.96875, 0.8359375, 0.67578125, 0.53515625, 0.431640625, 0.361328125, 0.3046875, 0.25, 0.2041015625, 0.177734375, 0.1591796875, 0.1376953125, 0.119140625, 0.10546875, 0.09326171875, 0.07666015625, 0.06494140625, 0.056396484375, 0.05078125, 0.05224609375, 0.052734375, 0.04931640625, 0.044677734375, 0.04541015625, 0.043212890625, 0.039306640625, 0.041748046875, 0.0419921875, 0.0419921875, 0.041259765625, 0.039306640625] [1.078125, 0.953125, 0.7890625, 0.6640625, 0.52734375, 0.39453125, 0.3046875, 0.26171875, 0.240234375, 0.2021484375, 0.1630859375, 0.1337890625, 0.11865234375, 0.10400390625, 0.0908203125, 0.0732421875, 0.06396484375, 0.064453125, 0.06640625, 0.06201171875, 0.056396484375, 0.050537109375, 0.046875, 0.043212890625, 0.039306640625, 0.034912109375, 0.03173828125, 0.0306396484375, 0.030029296875, 0.0306396484375, 0.0281982421875] [1.0703125, 0.94921875, 0.80078125, 0.7109375, 0.55078125, 0.4453125, 0.35546875, 0.2890625, 0.259765625, 0.2255859375, 0.18359375, 0.15625, 0.126953125, 0.1103515625, 0.09228515625, 0.0693359375, 0.060546875, 0.0546875, 0.05322265625, 0.048095703125, 0.048828125, 0.048095703125, 0.04296875, 0.04052734375, 0.039306640625, 0.035888671875, 0.03271484375, 0.0302734375, 0.0279541015625] [1.078125, 0.98046875, 0.8125, 0.68359375, 0.55078125, 0.451171875, 0.3515625, 0.263671875, 0.2470703125, 0.20703125, 0.1640625, 0.134765625, 0.1240234375, 0.11376953125, 0.09912109375, 0.083984375, 0.0703125, 0.06640625, 0.058837890625, 0.0517578125, 0.053466796875, 0.051513671875, 0.044921875, 0.046875, 0.05078125, 0.046875, 0.040771484375, 0.04052734375, 0.044921875, 0.04052734375, 0.03662109375, 0.03759765625] [1.078125, 0.97265625, 0.80859375, 0.625, 0.515625, 0.451171875, 0.35546875, 0.294921875, 0.265625, 0.2333984375, 0.2041015625, 0.177734375, 0.1572265625, 0.142578125, 0.130859375, 0.11279296875, 0.10546875, 0.10546875, 0.09619140625, 0.083984375, 0.07763671875, 0.06884765625, 0.06640625, 0.0712890625, 0.0732421875, 0.0654296875, 0.061279296875, 0.0556640625, 0.049072265625, 0.04052734375, 0.03564453125, 0.039306640625] [1.0625, 0.9296875, 0.765625, 0.69140625, 0.5625, 0.421875, 0.306640625, 0.2470703125, 0.240234375, 0.2138671875, 0.1943359375, 0.162109375, 0.12353515625, 0.1015625, 0.0908203125, 0.07861328125, 0.07421875, 0.078125, 0.0693359375, 0.061279296875, 0.0517578125, 0.048095703125, 0.048095703125, 0.046875, 0.04541015625, 0.044189453125, 0.04052734375, 0.034423828125, 0.0322265625, 0.0279541015625] [1.078125, 0.9921875, 0.796875, 0.6328125, 0.5546875, 0.45703125, 0.376953125, 0.29296875, 0.248046875, 0.19921875, 0.16015625, 0.1298828125, 0.11181640625, 0.09619140625, 0.0888671875, 0.0810546875, 0.06787109375, 0.06640625, 0.06005859375, 0.05810546875, 0.05224609375, 0.044921875, 0.041748046875, 0.039794921875, 0.039306640625, 0.039794921875, 0.038330078125, 0.033203125, 0.0308837890625, 0.0296630859375] [1.0703125, 0.9921875, 0.8203125, 0.67578125, 0.54296875, 0.431640625, 0.341796875, 0.275390625, 0.21875, 0.1806640625, 0.1533203125, 0.1279296875, 0.109375, 0.09375, 0.08056640625, 0.0712890625, 0.061767578125, 0.0625, 0.053955078125, 0.05029296875, 0.044189453125, 0.039306640625, 0.034912109375, 0.033203125, 0.033935546875, 0.032470703125, 0.030029296875, 0.0257568359375] [1.0625, 1.0078125, 0.85546875, 0.7109375, 0.55078125, 0.4453125, 0.35546875, 0.3046875, 0.25, 0.2041015625, 0.185546875, 0.1708984375, 0.15625, 0.1494140625, 0.1318359375, 0.09912109375, 0.080078125, 0.0751953125, 0.06640625, 0.054443359375, 0.050537109375, 0.044189453125, 0.038330078125, 0.031005859375, 0.0306396484375, 0.03271484375, 0.0303955078125, 0.0291748046875] [1.0625, 0.90234375, 0.7109375, 0.58984375, 0.5078125, 0.392578125, 0.31640625, 0.26953125, 0.212890625, 0.1630859375, 0.1337890625, 0.11279296875, 0.09619140625, 0.08642578125, 0.0751953125, 0.0673828125, 0.0595703125, 0.051025390625, 0.043212890625, 0.038818359375, 0.035400390625, 0.0308837890625, 0.02880859375] [1.0859375, 0.98828125, 0.765625, 0.63671875, 0.53125, 0.39453125, 0.3046875, 0.240234375, 0.197265625, 0.15625, 0.12158203125, 0.10107421875, 0.08447265625, 0.083984375, 0.0791015625, 0.06494140625, 0.0634765625, 0.06005859375, 0.046875, 0.0380859375, 0.03564453125, 0.03125, 0.02880859375] [1.0703125, 1.0234375, 0.87109375, 0.6796875, 0.57421875, 0.470703125, 0.39453125, 0.291015625, 0.228515625, 0.181640625, 0.14453125, 0.11279296875, 0.08984375, 0.08447265625, 0.076171875, 0.061767578125, 0.053955078125, 0.0546875, 0.047607421875, 0.042236328125, 0.036865234375, 0.0303955078125, 0.0263671875] [1.078125, 0.97265625, 0.796875, 0.66015625, 0.53515625, 0.404296875, 0.330078125, 0.26953125, 0.220703125, 0.1875, 0.16796875, 0.1416015625, 0.12255859375, 0.1015625, 0.0849609375, 0.0693359375, 0.060791015625, 0.056884765625, 0.050537109375, 0.0439453125, 0.0419921875, 0.03857421875, 0.034912109375, 0.0303955078125, 0.02587890625] [1.0703125, 0.875, 0.73828125, 0.65234375, 0.5390625, 0.45703125, 0.369140625, 0.3203125, 0.2734375, 0.2333984375, 0.1904296875, 0.150390625, 0.11865234375, 0.09619140625, 0.078125, 0.06640625, 0.0634765625, 0.05517578125, 0.046630859375, 0.040771484375, 0.0341796875, 0.031982421875, 0.0284423828125] [1.0703125, 0.89453125, 0.70703125, 0.609375, 0.515625, 0.408203125, 0.326171875, 0.2734375, 0.2255859375, 0.1845703125, 0.1572265625, 0.1328125, 0.10546875, 0.08154296875, 0.06591796875, 0.056396484375, 0.055908203125, 0.0517578125, 0.046630859375, 0.037841796875, 0.03369140625, 0.030029296875, 0.0252685546875] [1.1015625, 0.9609375, 0.82421875, 0.7109375, 0.578125, 0.451171875, 0.375, 0.2890625, 0.2470703125, 0.220703125, 0.173828125, 0.1474609375, 0.13671875, 0.1279296875, 0.0986328125, 0.07861328125, 0.06396484375, 0.059326171875, 0.051513671875, 0.048095703125, 0.042724609375, 0.039794921875, 0.034423828125, 0.031494140625, 0.02880859375] [1.078125, 0.9609375, 0.7890625, 0.6953125, 0.609375, 0.51171875, 0.41015625, 0.33984375, 0.279296875, 0.21875, 0.1689453125, 0.146484375, 0.1298828125, 0.109375, 0.09521484375, 0.0791015625, 0.06591796875, 0.058349609375, 0.049560546875, 0.045166015625, 0.04150390625, 0.038818359375, 0.034912109375, 0.0303955078125, 0.0279541015625] [1.09375, 0.98828125, 0.8046875, 0.69140625, 0.55859375, 0.431640625, 0.365234375, 0.296875, 0.2275390625, 0.1767578125, 0.140625, 0.11767578125, 0.1044921875, 0.08935546875, 0.076171875, 0.06787109375, 0.05712890625, 0.049560546875, 0.04248046875, 0.0400390625, 0.0361328125, 0.033203125, 0.0306396484375, 0.026611328125] [1.0625, 0.94140625, 0.8046875, 0.671875, 0.57421875, 0.474609375, 0.39453125, 0.33203125, 0.28515625, 0.23046875, 0.19140625, 0.15234375, 0.126953125, 0.1025390625, 0.083984375, 0.0712890625, 0.06396484375, 0.0595703125, 0.053955078125, 0.049072265625, 0.046630859375, 0.0439453125, 0.041015625, 0.03564453125, 0.0341796875, 0.032470703125, 0.0267333984375] [1.0703125, 0.94140625, 0.8203125, 0.6875, 0.5703125, 0.466796875, 0.375, 0.32421875, 0.265625, 0.2109375, 0.1630859375, 0.140625, 0.1318359375, 0.11767578125, 0.1025390625, 0.08837890625, 0.0771484375, 0.0693359375, 0.053466796875, 0.040283203125, 0.03662109375, 0.038330078125, 0.041259765625, 0.042236328125, 0.03955078125, 0.034423828125, 0.0322265625, 0.03125, 0.026123046875] [1.0859375, 0.93359375, 0.79296875, 0.671875, 0.58203125, 0.484375, 0.421875, 0.359375, 0.29296875, 0.2373046875, 0.1923828125, 0.1513671875, 0.1337890625, 0.11767578125, 0.10107421875, 0.0908203125, 0.08740234375, 0.08544921875, 0.068359375, 0.05712890625, 0.05322265625, 0.049072265625, 0.0458984375, 0.04736328125, 0.04638671875, 0.040283203125, 0.03173828125, 0.027587890625] [1.0859375, 0.9609375, 0.85546875, 0.734375, 0.6484375, 0.51953125, 0.38671875, 0.349609375, 0.306640625, 0.2451171875, 0.1953125, 0.1591796875, 0.13671875, 0.12158203125, 0.10400390625, 0.09619140625, 0.08544921875, 0.072265625, 0.056396484375, 0.0478515625, 0.040283203125, 0.0380859375, 0.036376953125, 0.03662109375, 0.03369140625, 0.0303955078125, 0.0267333984375] [1.09375, 0.9921875, 0.80078125, 0.71875, 0.6171875, 0.490234375, 0.38671875, 0.306640625, 0.26171875, 0.2255859375, 0.1962890625, 0.171875, 0.150390625, 0.1279296875, 0.10400390625, 0.0849609375, 0.0703125, 0.06201171875, 0.0556640625, 0.04443359375, 0.035400390625, 0.031005859375, 0.030029296875, 0.0322265625, 0.031982421875, 0.034423828125, 0.033203125, 0.0281982421875] [1.09375, 1.0078125, 0.828125, 0.71484375, 0.59765625, 0.466796875, 0.361328125, 0.29296875, 0.2451171875, 0.2421875, 0.2060546875, 0.177734375, 0.1513671875, 0.12109375, 0.09326171875, 0.072265625, 0.06201171875, 0.0517578125, 0.045166015625, 0.039306640625, 0.034912109375, 0.0322265625, 0.029052734375] [1.0703125, 1.0, 0.8359375, 0.703125, 0.5625, 0.48046875, 0.380859375, 0.3046875, 0.255859375, 0.248046875, 0.2001953125, 0.1708984375, 0.1474609375, 0.12109375, 0.1064453125, 0.0927734375, 0.07763671875, 0.06396484375, 0.04931640625, 0.041015625, 0.033203125, 0.033447265625, 0.0306396484375, 0.0281982421875] [1.0859375, 0.98046875, 0.83203125, 0.703125, 0.53125, 0.396484375, 0.326171875, 0.2734375, 0.2275390625, 0.212890625, 0.1923828125, 0.169921875, 0.1474609375, 0.1318359375, 0.119140625, 0.109375, 0.09423828125, 0.0830078125, 0.076171875, 0.061767578125, 0.0498046875, 0.044189453125, 0.037353515625, 0.032958984375, 0.0308837890625, 0.031005859375, 0.028564453125] [1.0625, 0.93359375, 0.765625, 0.62890625, 0.470703125, 0.365234375, 0.345703125, 0.30859375, 0.25, 0.212890625, 0.1962890625, 0.166015625, 0.1376953125, 0.1201171875, 0.111328125, 0.09814453125, 0.0859375, 0.07373046875, 0.06640625, 0.058349609375, 0.0517578125, 0.0439453125, 0.0380859375, 0.033203125, 0.0303955078125, 0.0281982421875] [1.078125, 0.9609375, 0.78515625, 0.625, 0.48046875, 0.37109375, 0.275390625, 0.2333984375, 0.1904296875, 0.169921875, 0.166015625, 0.1328125, 0.1015625, 0.0888671875, 0.0732421875, 0.0712890625, 0.06396484375, 0.05517578125, 0.054443359375, 0.04443359375, 0.0380859375, 0.035400390625, 0.031494140625, 0.0294189453125] [1.0859375, 0.9296875, 0.78125, 0.671875, 0.55859375, 0.455078125, 0.3515625, 0.279296875, 0.2255859375, 0.1943359375, 0.162109375, 0.138671875, 0.12255859375, 0.1201171875, 0.11279296875, 0.09619140625, 0.0810546875, 0.06787109375, 0.06494140625, 0.0625, 0.060791015625, 0.0654296875, 0.064453125, 0.056884765625, 0.049072265625, 0.041015625, 0.03271484375, 0.02978515625] [1.0859375, 0.953125, 0.82421875, 0.671875, 0.5390625, 0.447265625, 0.37890625, 0.32421875, 0.25390625, 0.197265625, 0.1708984375, 0.13671875, 0.11767578125, 0.10546875, 0.09423828125, 0.09033203125, 0.08349609375, 0.0732421875, 0.0673828125, 0.058349609375, 0.050048828125, 0.04443359375, 0.042724609375, 0.041015625, 0.037109375, 0.034423828125, 0.0322265625, 0.028564453125] [1.1015625, 0.9296875, 0.80078125, 0.73046875, 0.625, 0.51171875, 0.400390625, 0.3359375, 0.2734375, 0.2158203125, 0.1875, 0.158203125, 0.134765625, 0.11669921875, 0.09521484375, 0.083984375, 0.0703125, 0.058349609375, 0.054443359375, 0.046875, 0.0419921875, 0.038330078125, 0.0400390625, 0.03564453125, 0.0308837890625, 0.028564453125] [1.0859375, 0.90234375, 0.7890625, 0.66015625, 0.56640625, 0.4765625, 0.4140625, 0.345703125, 0.28515625, 0.2333984375, 0.2001953125, 0.1611328125, 0.12890625, 0.111328125, 0.0927734375, 0.0810546875, 0.07666015625, 0.0625, 0.051513671875, 0.0478515625, 0.043212890625, 0.03759765625, 0.03759765625, 0.033447265625, 0.0284423828125] [1.0703125, 0.96875, 0.8515625, 0.7109375, 0.57421875, 0.470703125, 0.390625, 0.345703125, 0.28515625, 0.2333984375, 0.201171875, 0.162109375, 0.134765625, 0.109375, 0.08642578125, 0.08544921875, 0.08349609375, 0.0732421875, 0.068359375, 0.0556640625, 0.041748046875, 0.03466796875, 0.034423828125, 0.0380859375, 0.041015625, 0.0400390625, 0.03857421875, 0.03515625, 0.0284423828125] [1.1015625, 0.94140625, 0.8046875, 0.6875, 0.5546875, 0.45703125, 0.375, 0.3203125, 0.255859375, 0.212890625, 0.1943359375, 0.16015625, 0.1337890625, 0.111328125, 0.08447265625, 0.078125, 0.07177734375, 0.060791015625, 0.0517578125, 0.04638671875, 0.040283203125, 0.036865234375, 0.038818359375, 0.034912109375, 0.03125, 0.0279541015625] [1.1015625, 0.94921875, 0.8046875, 0.69921875, 0.578125, 0.515625, 0.431640625, 0.375, 0.328125, 0.296875, 0.263671875, 0.23046875, 0.20703125, 0.1884765625, 0.1474609375, 0.125, 0.1044921875, 0.0810546875, 0.06884765625, 0.061279296875, 0.0556640625, 0.048583984375, 0.04248046875, 0.039306640625, 0.03759765625, 0.03466796875, 0.031982421875, 0.0294189453125] [1.1015625, 0.9609375, 0.81640625, 0.67578125, 0.58984375, 0.466796875, 0.375, 0.296875, 0.2333984375, 0.1884765625, 0.158203125, 0.130859375, 0.11279296875, 0.10107421875, 0.0849609375, 0.07080078125, 0.061767578125, 0.05029296875, 0.04638671875, 0.04052734375, 0.034423828125, 0.0308837890625, 0.0281982421875] [1.0859375, 0.9609375, 0.8359375, 0.73046875, 0.59765625, 0.4375, 0.337890625, 0.283203125, 0.2431640625, 0.203125, 0.1669921875, 0.138671875, 0.11767578125, 0.10205078125, 0.08447265625, 0.06884765625, 0.0576171875, 0.047119140625, 0.041259765625, 0.0361328125, 0.0308837890625, 0.025634765625] [1.0859375, 0.98046875, 0.83203125, 0.67578125, 0.546875, 0.4453125, 0.345703125, 0.279296875, 0.228515625, 0.2001953125, 0.1728515625, 0.1611328125, 0.1298828125, 0.10693359375, 0.0947265625, 0.07861328125, 0.06640625, 0.056396484375, 0.04638671875, 0.0400390625, 0.033447265625, 0.029052734375] [1.0703125, 0.96875, 0.82421875, 0.7109375, 0.578125, 0.455078125, 0.353515625, 0.287109375, 0.2373046875, 0.19140625, 0.1572265625, 0.12890625, 0.1044921875, 0.091796875, 0.08056640625, 0.0712890625, 0.06396484375, 0.060791015625, 0.056884765625, 0.05029296875, 0.042236328125, 0.036865234375, 0.031494140625, 0.02783203125] [1.078125, 0.94140625, 0.8203125, 0.7578125, 0.6640625, 0.5390625, 0.48046875, 0.48046875, 0.412109375, 0.318359375, 0.259765625, 0.189453125, 0.1416015625, 0.1142578125, 0.0986328125, 0.08740234375, 0.0732421875, 0.06787109375, 0.058349609375, 0.047607421875, 0.039794921875, 0.035888671875, 0.034423828125, 0.03125, 0.0267333984375] [1.078125, 0.94921875, 0.8203125, 0.7109375, 0.60546875, 0.51171875, 0.5078125, 0.5078125, 0.435546875, 0.357421875, 0.3125, 0.25390625, 0.208984375, 0.16796875, 0.138671875, 0.111328125, 0.08642578125, 0.0712890625, 0.06787109375, 0.06005859375, 0.048583984375, 0.045166015625, 0.0439453125, 0.0419921875, 0.037353515625, 0.031494140625, 0.0250244140625] [1.0859375, 0.93359375, 0.734375, 0.609375, 0.51171875, 0.3671875, 0.31640625, 0.267578125, 0.21875, 0.177734375, 0.15234375, 0.1279296875, 0.10400390625, 0.09619140625, 0.08447265625, 0.06640625, 0.053466796875, 0.046142578125, 0.0380859375, 0.03173828125, 0.02734375] [1.0703125, 0.94921875, 0.765625, 0.71875, 0.6171875, 0.515625, 0.53125, 0.474609375, 0.3828125, 0.30078125, 0.259765625, 0.197265625, 0.15625, 0.125, 0.10791015625, 0.09619140625, 0.08642578125, 0.0712890625, 0.058349609375, 0.050537109375, 0.046875, 0.04443359375, 0.040283203125, 0.0361328125, 0.0341796875, 0.02978515625] [1.0703125, 0.953125, 0.76171875, 0.67578125, 0.5546875, 0.435546875, 0.4140625, 0.369140625, 0.3046875, 0.265625, 0.212890625, 0.1708984375, 0.1572265625, 0.1337890625, 0.10009765625, 0.08642578125, 0.0732421875, 0.058837890625, 0.04833984375, 0.039306640625, 0.032470703125, 0.02978515625] [1.0703125, 0.96875, 0.765625, 0.63671875, 0.54296875, 0.421875, 0.35546875, 0.314453125, 0.263671875, 0.203125, 0.1572265625, 0.140625, 0.138671875, 0.1259765625, 0.1025390625, 0.08837890625, 0.0712890625, 0.052734375, 0.043212890625, 0.039306640625, 0.034423828125, 0.0308837890625, 0.02880859375] [1.0703125, 0.97265625, 0.7890625, 0.65234375, 0.5546875, 0.46484375, 0.390625, 0.33984375, 0.291015625, 0.251953125, 0.20703125, 0.166015625, 0.1328125, 0.103515625, 0.087890625, 0.07421875, 0.06201171875, 0.05322265625, 0.04736328125, 0.0419921875, 0.03515625, 0.0302734375, 0.02734375] [1.0703125, 0.93359375, 0.72265625, 0.6328125, 0.5234375, 0.4140625, 0.345703125, 0.28515625, 0.2421875, 0.201171875, 0.1669921875, 0.134765625, 0.12109375, 0.10205078125, 0.08154296875, 0.0595703125, 0.048828125, 0.043212890625, 0.03759765625, 0.033203125, 0.028564453125] [1.0703125, 0.921875, 0.74609375, 0.5859375, 0.5, 0.41015625, 0.341796875, 0.29296875, 0.255859375, 0.203125, 0.173828125, 0.15234375, 0.1337890625, 0.11181640625, 0.08740234375, 0.06787109375, 0.055908203125, 0.049560546875, 0.044189453125, 0.036865234375, 0.02978515625] [1.09375, 0.98828125, 0.8046875, 0.65625, 0.51171875, 0.37890625, 0.28515625, 0.25, 0.22265625, 0.197265625, 0.1611328125, 0.1396484375, 0.1259765625, 0.1044921875, 0.083984375, 0.076171875, 0.064453125, 0.051025390625, 0.0439453125, 0.04296875, 0.039306640625, 0.034423828125, 0.0294189453125] [1.0625, 0.9296875, 0.7890625, 0.625, 0.51953125, 0.40625, 0.318359375, 0.26953125, 0.2421875, 0.193359375, 0.162109375, 0.12890625, 0.109375, 0.09375, 0.08154296875, 0.06689453125, 0.053955078125, 0.043701171875, 0.037353515625, 0.032470703125, 0.0281982421875] [1.078125, 1.03125, 0.83203125, 0.703125, 0.5859375, 0.484375, 0.384765625, 0.314453125, 0.263671875, 0.2158203125, 0.1767578125, 0.1328125, 0.109375, 0.09130859375, 0.07958984375, 0.0712890625, 0.060791015625, 0.05517578125, 0.045654296875, 0.0380859375, 0.033203125, 0.0281982421875] [1.0859375, 0.98828125, 0.796875, 0.671875, 0.53125, 0.4609375, 0.40234375, 0.369140625, 0.32421875, 0.2578125, 0.208984375, 0.15625, 0.134765625, 0.12158203125, 0.0947265625, 0.072265625, 0.05810546875, 0.0517578125, 0.044677734375, 0.0380859375, 0.03662109375, 0.034912109375, 0.0308837890625, 0.0267333984375] [1.0859375, 0.93359375, 0.76171875, 0.6484375, 0.53125, 0.455078125, 0.384765625, 0.37109375, 0.3359375, 0.28515625, 0.2578125, 0.23828125, 0.1982421875, 0.1591796875, 0.1240234375, 0.09765625, 0.08837890625, 0.0693359375, 0.05712890625, 0.046875, 0.040283203125, 0.04052734375, 0.03759765625, 0.031494140625, 0.025634765625] [1.0859375, 0.94140625, 0.76171875, 0.59765625, 0.51171875, 0.40625, 0.365234375, 0.34765625, 0.3046875, 0.265625, 0.2275390625, 0.201171875, 0.173828125, 0.142578125, 0.11767578125, 0.0927734375, 0.07861328125, 0.061279296875, 0.05029296875, 0.04638671875, 0.03759765625, 0.03466796875, 0.0308837890625, 0.02783203125] [1.0625, 0.9296875, 0.76171875, 0.6328125, 0.5546875, 0.474609375, 0.376953125, 0.3125, 0.28125, 0.2333984375, 0.177734375, 0.146484375, 0.126953125, 0.10888671875, 0.08837890625, 0.068359375, 0.05810546875, 0.053955078125, 0.043212890625, 0.034423828125, 0.02978515625] [1.0859375, 1.015625, 0.83203125, 0.75, 0.62890625, 0.515625, 0.421875, 0.33984375, 0.265625, 0.21875, 0.177734375, 0.1435546875, 0.1240234375, 0.1103515625, 0.09375, 0.0888671875, 0.07666015625, 0.06005859375, 0.04931640625, 0.0419921875, 0.034912109375, 0.0294189453125] [1.0859375, 1.0, 0.82421875, 0.73046875, 0.58203125, 0.486328125, 0.396484375, 0.333984375, 0.271484375, 0.21875, 0.1826171875, 0.1474609375, 0.11181640625, 0.09423828125, 0.08154296875, 0.07861328125, 0.06884765625, 0.058349609375, 0.05224609375, 0.049560546875, 0.0400390625, 0.031982421875, 0.0269775390625] [1.0703125, 1.0234375, 0.8515625, 0.73046875, 0.66796875, 0.5390625, 0.45703125, 0.38671875, 0.28515625, 0.20703125, 0.16796875, 0.1376953125, 0.10693359375, 0.08447265625, 0.076171875, 0.06787109375, 0.058349609375, 0.05322265625, 0.04736328125, 0.043701171875, 0.0380859375, 0.03125, 0.0267333984375] [1.078125, 0.9609375, 0.81640625, 0.73828125, 0.58984375, 0.5078125, 0.435546875, 0.369140625, 0.279296875, 0.22265625, 0.173828125, 0.13671875, 0.11181640625, 0.10205078125, 0.0908203125, 0.07568359375, 0.0693359375, 0.05712890625, 0.045166015625, 0.036865234375, 0.03125, 0.02734375] [1.0625, 0.96875, 0.83203125, 0.71875, 0.578125, 0.474609375, 0.404296875, 0.39453125, 0.33984375, 0.2734375, 0.20703125, 0.15625, 0.140625, 0.119140625, 0.1064453125, 0.08935546875, 0.07373046875, 0.058837890625, 0.05224609375, 0.048095703125, 0.038818359375, 0.03271484375, 0.0294189453125] [1.078125, 1.0234375, 0.83203125, 0.68359375, 0.53125, 0.42578125, 0.365234375, 0.326171875, 0.27734375, 0.2275390625, 0.1845703125, 0.16015625, 0.142578125, 0.11767578125, 0.1025390625, 0.0869140625, 0.0810546875, 0.0732421875, 0.06396484375, 0.060791015625, 0.05126953125, 0.039306640625, 0.031494140625, 0.0291748046875] [1.078125, 1.0078125, 0.8125, 0.625, 0.490234375, 0.408203125, 0.359375, 0.296875, 0.2470703125, 0.2001953125, 0.16015625, 0.138671875, 0.11181640625, 0.09423828125, 0.08447265625, 0.0712890625, 0.068359375, 0.059326171875, 0.0546875, 0.051513671875, 0.041015625, 0.03369140625, 0.0294189453125] [1.078125, 1.0234375, 0.8515625, 0.61328125, 0.494140625, 0.396484375, 0.341796875, 0.28515625, 0.232421875, 0.20703125, 0.17578125, 0.1455078125, 0.1142578125, 0.09423828125, 0.08740234375, 0.0791015625, 0.06640625, 0.058349609375, 0.052001953125, 0.048095703125, 0.03955078125, 0.031982421875, 0.02783203125] [1.078125, 0.9921875, 0.8125, 0.6875, 0.55078125, 0.390625, 0.302734375, 0.2333984375, 0.2158203125, 0.1875, 0.15234375, 0.12158203125, 0.109375, 0.08984375, 0.07470703125, 0.058837890625, 0.052734375, 0.046630859375, 0.044189453125, 0.041015625, 0.033447265625, 0.0303955078125, 0.0291748046875] [1.0625, 1.015625, 0.81640625, 0.640625, 0.515625, 0.421875, 0.33203125, 0.28125, 0.2333984375, 0.1982421875, 0.158203125, 0.1357421875, 0.109375, 0.09765625, 0.08642578125, 0.0693359375, 0.061767578125, 0.0517578125, 0.0439453125, 0.0380859375, 0.033203125, 0.02880859375] [1.09375, 0.97265625, 0.82421875, 0.6796875, 0.53125, 0.42578125, 0.357421875, 0.29296875, 0.251953125, 0.201171875, 0.162109375, 0.138671875, 0.111328125, 0.09228515625, 0.078125, 0.061767578125, 0.053955078125, 0.05224609375, 0.04931640625, 0.04296875, 0.037353515625, 0.033447265625, 0.034423828125, 0.0306396484375, 0.032470703125, 0.031494140625, 0.0281982421875] [1.0625, 1.0078125, 0.81640625, 0.6484375, 0.55078125, 0.455078125, 0.384765625, 0.32421875, 0.287109375, 0.2421875, 0.205078125, 0.171875, 0.146484375, 0.1298828125, 0.12353515625, 0.1103515625, 0.09521484375, 0.080078125, 0.0654296875, 0.053466796875, 0.045654296875, 0.0390625, 0.03466796875, 0.03173828125, 0.0322265625, 0.031494140625, 0.0302734375, 0.0260009765625] [1.0703125, 0.94140625, 0.8203125, 0.7109375, 0.58203125, 0.50390625, 0.435546875, 0.345703125, 0.27734375, 0.220703125, 0.1728515625, 0.138671875, 0.11181640625, 0.0947265625, 0.07861328125, 0.06689453125, 0.05712890625, 0.05078125, 0.045166015625, 0.04052734375, 0.033203125, 0.02880859375] [1.0859375, 0.9921875, 0.8515625, 0.6875, 0.58203125, 0.455078125, 0.40234375, 0.31640625, 0.2373046875, 0.1953125, 0.162109375, 0.12890625, 0.11279296875, 0.09033203125, 0.080078125, 0.07080078125, 0.060546875, 0.048583984375, 0.04150390625, 0.0380859375, 0.031005859375, 0.0302734375, 0.026611328125] [1.0859375, 0.98046875, 0.87109375, 0.6796875, 0.69921875, 0.6171875, 0.51171875, 0.431640625, 0.34375, 0.255859375, 0.201171875, 0.17578125, 0.1416015625, 0.12353515625, 0.109375, 0.0888671875, 0.0732421875, 0.060546875, 0.048583984375, 0.041259765625, 0.033935546875, 0.027587890625] [1.0703125, 0.953125, 0.828125, 0.65234375, 0.6015625, 0.57421875, 0.4765625, 0.40625, 0.3359375, 0.2578125, 0.2060546875, 0.166015625, 0.14453125, 0.11865234375, 0.09619140625, 0.07958984375, 0.07080078125, 0.05712890625, 0.046875, 0.042236328125, 0.03564453125, 0.02978515625] [1.078125, 0.97265625, 0.81640625, 0.69140625, 0.58984375, 0.490234375, 0.427734375, 0.33984375, 0.275390625, 0.2353515625, 0.193359375, 0.1494140625, 0.126953125, 0.10888671875, 0.08642578125, 0.0712890625, 0.06591796875, 0.0595703125, 0.050048828125, 0.043701171875, 0.036865234375, 0.030029296875, 0.025390625] [1.078125, 0.97265625, 0.7890625, 0.6953125, 0.609375, 0.494140625, 0.408203125, 0.36328125, 0.298828125, 0.2353515625, 0.185546875, 0.1591796875, 0.12890625, 0.11181640625, 0.0966796875, 0.08544921875, 0.0712890625, 0.06640625, 0.05810546875, 0.047607421875, 0.039794921875, 0.0341796875, 0.0296630859375] [1.09375, 0.953125, 0.80859375, 0.671875, 0.578125, 0.490234375, 0.41796875, 0.34765625, 0.27734375, 0.220703125, 0.1767578125, 0.154296875, 0.13671875, 0.1162109375, 0.10546875, 0.0830078125, 0.0673828125, 0.055908203125, 0.048583984375, 0.04345703125, 0.0419921875, 0.03857421875, 0.034423828125, 0.0267333984375] [1.0703125, 0.9609375, 0.828125, 0.6796875, 0.5859375, 0.5, 0.42578125, 0.341796875, 0.265625, 0.2021484375, 0.166015625, 0.1298828125, 0.10888671875, 0.09765625, 0.08837890625, 0.0712890625, 0.0556640625, 0.04638671875, 0.04150390625, 0.037353515625, 0.03369140625, 0.029052734375] [1.0703125, 0.98828125, 0.85546875, 0.703125, 0.5703125, 0.46484375, 0.435546875, 0.349609375, 0.271484375, 0.1953125, 0.15234375, 0.1201171875, 0.0986328125, 0.0791015625, 0.06640625, 0.05810546875, 0.04541015625, 0.041259765625, 0.043212890625, 0.037353515625, 0.031982421875, 0.0281982421875] [1.078125, 0.97265625, 0.828125, 0.6796875, 0.55078125, 0.455078125, 0.35546875, 0.294921875, 0.2421875, 0.18359375, 0.146484375, 0.1162109375, 0.09423828125, 0.07568359375, 0.06201171875, 0.051025390625, 0.041015625, 0.03515625, 0.030029296875, 0.0267333984375] [1.0546875, 0.94140625, 0.85546875, 0.71875, 0.625, 0.5, 0.421875, 0.357421875, 0.275390625, 0.2109375, 0.1689453125, 0.130859375, 0.1103515625, 0.095703125, 0.0888671875, 0.07763671875, 0.06591796875, 0.055908203125, 0.0478515625, 0.042236328125, 0.036376953125, 0.034423828125, 0.0291748046875] [1.0859375, 0.9609375, 0.87109375, 0.73046875, 0.625, 0.5625, 0.49609375, 0.42578125, 0.361328125, 0.283203125, 0.208984375, 0.1484375, 0.10791015625, 0.0810546875, 0.06884765625, 0.056396484375, 0.046875, 0.0380859375, 0.03271484375, 0.02783203125] [1.078125, 0.97265625, 0.890625, 0.7578125, 0.609375, 0.490234375, 0.42578125, 0.345703125, 0.275390625, 0.22265625, 0.1865234375, 0.1708984375, 0.1455078125, 0.11279296875, 0.09130859375, 0.07861328125, 0.060546875, 0.04833984375, 0.0400390625, 0.03466796875, 0.031005859375, 0.0269775390625] [1.0859375, 0.93359375, 0.80078125, 0.6875, 0.5546875, 0.466796875, 0.37890625, 0.314453125, 0.259765625, 0.20703125, 0.177734375, 0.1474609375, 0.11767578125, 0.1025390625, 0.0859375, 0.06884765625, 0.058349609375, 0.0517578125, 0.04443359375, 0.03955078125, 0.033935546875, 0.0294189453125] [1.0625, 0.96875, 0.875, 0.8359375, 0.671875, 0.57421875, 0.515625, 0.40234375, 0.328125, 0.27734375, 0.251953125, 0.2138671875, 0.1826171875, 0.1513671875, 0.126953125, 0.1015625, 0.0830078125, 0.076171875, 0.06591796875, 0.05224609375, 0.045166015625, 0.045654296875, 0.038818359375, 0.032958984375, 0.031982421875, 0.0303955078125, 0.02734375] [1.0859375, 0.98046875, 0.85546875, 0.75, 0.671875, 0.61328125, 0.53125, 0.470703125, 0.392578125, 0.3359375, 0.265625, 0.2060546875, 0.1748046875, 0.14453125, 0.11767578125, 0.1015625, 0.0888671875, 0.0751953125, 0.0673828125, 0.061279296875, 0.054443359375, 0.05029296875, 0.046875, 0.040283203125, 0.041015625, 0.039306640625, 0.03759765625, 0.031005859375, 0.0245361328125] [1.078125, 0.94140625, 0.75, 0.62109375, 0.53125, 0.427734375, 0.322265625, 0.2421875, 0.1982421875, 0.1650390625, 0.138671875, 0.11669921875, 0.1015625, 0.08740234375, 0.07275390625, 0.058349609375, 0.05712890625, 0.048583984375, 0.042724609375, 0.036865234375, 0.03271484375, 0.0291748046875] [1.078125, 0.98046875, 0.8125, 0.75, 0.66015625, 0.466796875, 0.373046875, 0.314453125, 0.275390625, 0.232421875, 0.1865234375, 0.1552734375, 0.1337890625, 0.12353515625, 0.1025390625, 0.07861328125, 0.061279296875, 0.050048828125, 0.045166015625, 0.038330078125, 0.03466796875, 0.036865234375, 0.0341796875, 0.03125, 0.0296630859375] [1.0625, 0.9921875, 0.87109375, 0.6953125, 0.55078125, 0.427734375, 0.32421875, 0.240234375, 0.22265625, 0.1923828125, 0.1640625, 0.1328125, 0.10693359375, 0.0888671875, 0.07275390625, 0.0576171875, 0.051513671875, 0.048583984375, 0.043701171875, 0.038818359375, 0.038330078125, 0.0380859375, 0.03515625, 0.039306640625, 0.043701171875, 0.0419921875, 0.0380859375, 0.0296630859375] [1.0703125, 0.98046875, 0.8828125, 0.7890625, 0.67578125, 0.51171875, 0.3984375, 0.2890625, 0.2373046875, 0.2109375, 0.18359375, 0.154296875, 0.15234375, 0.1396484375, 0.11279296875, 0.0927734375, 0.07275390625, 0.059326171875, 0.052001953125, 0.0458984375, 0.043701171875, 0.040283203125, 0.0380859375, 0.03857421875, 0.039794921875, 0.04248046875, 0.039306640625, 0.031005859375, 0.02587890625] [1.0625, 1.0078125, 0.84375, 0.76171875, 0.6484375, 0.55078125, 0.455078125, 0.373046875, 0.28515625, 0.228515625, 0.1865234375, 0.154296875, 0.130859375, 0.10693359375, 0.08837890625, 0.0703125, 0.06591796875, 0.055908203125, 0.048095703125, 0.040771484375, 0.0380859375, 0.035888671875, 0.033203125, 0.031982421875, 0.034423828125, 0.034912109375, 0.0322265625, 0.0267333984375] [1.09375, 0.9609375, 0.85546875, 0.7265625, 0.609375, 0.53125, 0.46484375, 0.337890625, 0.2470703125, 0.197265625, 0.154296875, 0.1279296875, 0.10693359375, 0.10302734375, 0.09326171875, 0.0732421875, 0.055908203125, 0.048095703125, 0.04296875, 0.038330078125, 0.033447265625, 0.0306396484375, 0.0269775390625] [1.0703125, 0.94921875, 0.81640625, 0.71484375, 0.609375, 0.56640625, 0.51171875, 0.421875, 0.33984375, 0.2734375, 0.2177734375, 0.1875, 0.1708984375, 0.1689453125, 0.1474609375, 0.1162109375, 0.0927734375, 0.0732421875, 0.06396484375, 0.05224609375, 0.048095703125, 0.04052734375, 0.0380859375, 0.036865234375, 0.034423828125, 0.03271484375, 0.031982421875, 0.027587890625] [1.078125, 0.96875, 0.890625, 0.7734375, 0.6953125, 0.625, 0.515625, 0.404296875, 0.337890625, 0.27734375, 0.2353515625, 0.2001953125, 0.162109375, 0.140625, 0.11669921875, 0.0986328125, 0.0830078125, 0.0673828125, 0.05810546875, 0.051025390625, 0.0478515625, 0.041259765625, 0.037841796875, 0.041748046875, 0.041748046875, 0.043212890625, 0.0419921875, 0.03515625, 0.0291748046875] [1.078125, 0.98828125, 0.79296875, 0.6484375, 0.51171875, 0.466796875, 0.412109375, 0.330078125, 0.265625, 0.2138671875, 0.1923828125, 0.1640625, 0.1435546875, 0.134765625, 0.109375, 0.0849609375, 0.0732421875, 0.0673828125, 0.06494140625, 0.061767578125, 0.0576171875, 0.05078125, 0.045166015625, 0.043701171875, 0.04345703125, 0.042724609375, 0.0419921875, 0.036376953125, 0.0296630859375] [1.0859375, 0.9921875, 0.78515625, 0.65625, 0.56640625, 0.4765625, 0.435546875, 0.345703125, 0.26953125, 0.205078125, 0.169921875, 0.146484375, 0.1455078125, 0.1240234375, 0.111328125, 0.0947265625, 0.07763671875, 0.06640625, 0.0546875, 0.050537109375, 0.04736328125, 0.04052734375, 0.040771484375, 0.035888671875, 0.032958984375, 0.031982421875, 0.0294189453125] [1.1015625, 0.90234375, 0.78125, 0.66796875, 0.56640625, 0.470703125, 0.376953125, 0.3203125, 0.265625, 0.21875, 0.212890625, 0.1923828125, 0.15625, 0.1318359375, 0.10400390625, 0.0947265625, 0.083984375, 0.07568359375, 0.07080078125, 0.0654296875, 0.0712890625, 0.06591796875, 0.06396484375, 0.072265625, 0.06494140625, 0.058349609375, 0.05712890625, 0.05224609375, 0.061279296875, 0.058837890625, 0.047119140625, 0.054443359375] [1.09375, 0.98828125, 0.7890625, 0.66015625, 0.59375, 0.50390625, 0.447265625, 0.375, 0.30859375, 0.263671875, 0.2177734375, 0.185546875, 0.1494140625, 0.1318359375, 0.1015625, 0.0859375, 0.0712890625, 0.061767578125, 0.050537109375, 0.046630859375, 0.050537109375, 0.046875, 0.041748046875, 0.040771484375, 0.0390625, 0.0380859375, 0.03662109375, 0.03125, 0.026123046875] [1.078125, 0.98046875, 0.87109375, 0.7890625, 0.66015625, 0.609375, 0.55078125, 0.46484375, 0.404296875, 0.35546875, 0.283203125, 0.212890625, 0.1767578125, 0.1474609375, 0.1201171875, 0.09521484375, 0.07958984375, 0.072265625, 0.06396484375, 0.053955078125, 0.04931640625, 0.045654296875, 0.03955078125, 0.03564453125, 0.031982421875, 0.0284423828125]\n"
     ]
    }
   ],
   "source": [
    "# Conservative\n",
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer,\n",
    "                                    continuous_compute=False, criterion=\"latent-diff\", exit_threshold=\"auto\", cache_lookup_strategy=\"latest-m4\")\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")\n",
    "print(*[val[0][0] for val in outputs.scores])\n",
    "print(*[val[1][-1] for val in outputs.scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we need to follow these steps:\n",
      "\n",
      "1. Calculate the number of eggs in a dozen:\n",
      "   - 1 dozen = 12 eggs\n",
      "\n",
      "2. Calculate the number of eggs in 4 weeks:\n",
      "   - 4 weeks = 4 * 7 days = 28 days\n",
      "   - 28 days = 28 * 12 eggs = 336 eggs\n",
      "\n",
      "3. Calculate the number of dozens of eggs:\n",
      "   - 336 eggs / 12 eggs per dozen = 28 dozens\n",
      "\n",
      "Therefore, Claire will eat 28 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 390.66650390625MB\n",
      "14 23 25 11 11 13 11 11 14 12 12 12 12 11 11 12 12 11 18 15 11 11 11 11 11 20 11 16 11 11 18 14 16 25 11 13 18 13 13 13 11 12 17 19 11 11 0 11 11 11 11 11 15 12 11 11 11 11 13 11 11 11 27 18 15 12 14 15 15 14 11 11 13 14 11 11 12 15 15 22 12 22 11 16 21 13 14 12 11 11 26 11 13 11 18 11 11 15 11 11 11 16 12 12 12 14 15 16 14 23 15 11 24 20 18 16 17 11 13 11 12 11 11 15 11 11 11 12 11 11 11\n",
      "[0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 0, 1, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 3, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 1, 2, 0, 1, 2, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 0, 1, 2, 3, 0, 0, 1, 2, 3, 4, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 0, 0, 1, 0, 0, 1, 2, 3, 4, 5, 0, 1, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 0, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 0, 1, 0, 1, 2, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 0, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 0, 1, 0, 0, 1, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 0, 1, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# More aggressive\n",
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer,\n",
    "                                    continuous_compute=False, criterion=\"argmax-stability\", exit_threshold=10, cache_lookup_strategy=\"latest-m4\")\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")\n",
    "print(*[val[0][0] for val in outputs.scores])\n",
    "print(*[val[1][-1] for val in outputs.scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>system<|end_header|>\n",
      "\n",
      "You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
      "\n",
      "Methodical reasoning, breaking complex problems into clear steps\n",
      "Mathematical and programming expertise grounded in fundamentals\n",
      "The ability to acknowledge uncertainty and correct course when needed\n",
      "Clear communication that illuminates rather than just informs\n",
      "\n",
      "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
      "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.<|end_turn|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we must first understand the number of eggs in a dozen. A dozen is 12 eggs. \n",
      "\n",
      "Now, let's calculate the total number of eggs in 4 weeks. Since Claire makes a 3 egg omelet every morning, she will make 3 omelets per day. There are 7 days in a week, so in 4 weeks, she will make 3 omelets/day * 7 days/week * 4 weeks = 84 omelets.\n",
      "\n",
      "Finally, we can calculate the total number of eggs in 4 weeks. Since there are 12 eggs in a dozen, we divide the total number of eggs by 12 to find the number of dozens. 84 eggs / 12 eggs/dozen = 7 dozens.\n",
      "\n",
      "Therefore, Claire will eat 7 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 147.4365234375MB\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer, cache_lookup_strategy=\"latest-m4-compress-s16\")\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>system<|end_header|>\n",
      "\n",
      "You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
      "\n",
      "Methodical reasoning, breaking complex problems into clear steps\n",
      "Mathematical and programming expertise grounded in fundamentals\n",
      "The ability to acknowledge uncertainty and correct course when needed\n",
      "Clear communication that illuminates rather than just informs\n",
      "\n",
      "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
      "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.<|end_turn|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we must first understand the number of eggs in a dozen. A dozen is 12 eggs. \n",
      "\n",
      "Now, let's calculate the total number of eggs in 4 weeks. Since Claire makes a 3 egg omelet every morning, she will make 3 omelets per day. There are 7 days in a week, so in 4 weeks, she will make 3 omelets/day * 7 days/week * 4 weeks = 84 omelets.\n",
      "\n",
      "Finally, we can calculate the total number of dozens of eggs by dividing the total number of omelets by the number of eggs in a dozen. 84 omelets / 12 eggs/dozen = 7 dozens.\n",
      "\n",
      "Therefore, Claire will eat 7 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 286.0107421875MB\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer, cache_lookup_strategy=\"latest-m4-compress-anchor\")\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Sharing and Adaptive Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we must first understand the number of eggs in a dozen. A dozen is 12 eggs. \n",
      "\n",
      "Now, let's calculate the total number of eggs in 4 weeks. Since Claire makes a 3 egg omelet every morning, she will make 3 omelets per day. There are 7 days in a week, so in 4 weeks, she will make 3 omelets/day * 7 days/week * 4 weeks = 84 omelets.\n",
      "\n",
      "Finally, we can calculate the total number of eggs in 4 weeks. Since there are 12 eggs in a dozen, we divide the total number of eggs by 12 to find the number of dozens. 84 eggs / 12 eggs/dozen = 7 dozens.\n",
      "\n",
      "Therefore, Claire will eat 7 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 147.4365234375MB\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer, \n",
    "                         criterion=\"latent-diff\", exit_threshold=\"auto\", cache_lookup_strategy=\"latest-m4-compress-s16\")\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the static cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>system<|end_header|>\n",
      "\n",
      "You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
      "\n",
      "Methodical reasoning, breaking complex problems into clear steps\n",
      "Mathematical and programming expertise grounded in fundamentals\n",
      "The ability to acknowledge uncertainty and correct course when needed\n",
      "Clear communication that illuminates rather than just informs\n",
      "\n",
      "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
      "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.<|end_turn|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we must first understand the number of eggs in a dozen. A dozen is 12 eggs. \n",
      "\n",
      "Now, let's calculate the total number of eggs in 4 weeks. Since Claire makes a 3 egg omelet every morning, she will make 3 omelets per day. There are 7 days in a week, so in 4 weeks, she will make 3 omelets/day * 7 days/week * 4 weeks = 84 omelets.\n",
      "\n",
      "Finally, we can calculate the total number of eggs in 4 weeks. Since there are 12 eggs in a dozen, we divide the total number of eggs by 12 to find the number of dozens. 84 eggs / 12 eggs/dozen = 7 dozens.\n",
      "\n",
      "Therefore, Claire will eat 7 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 2722.5MB\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer, cache_implementation=\"static\", disable_compile=True)\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling (min-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>system<|end_header|>\n",
      "\n",
      "You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
      "\n",
      "Methodical reasoning, breaking complex problems into clear steps\n",
      "Mathematical and programming expertise grounded in fundamentals\n",
      "The ability to acknowledge uncertainty and correct course when needed\n",
      "Clear communication that illuminates rather than just informs\n",
      "\n",
      "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
      "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.<|end_turn|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "To calculate the number of dozens of eggs Claire will eat in 4 weeks, we need to determine the total number of eggs she eats in a week and then multiply it by the number of weeks.\n",
      "\n",
      "Step 1: Determine the total number of eggs in a week.\n",
      "Since Claire makes a 3 egg omelet every morning, we can assume she eats 3 eggs per day. To find out how many eggs she eats in a week, we need to know how many days are in a week.\n",
      "\n",
      "Assuming a standard week has 7 days, we can calculate the number of eggs in a week as follows:\n",
      "Eggs per week = Eggs per day * Days per week\n",
      "Eggs per week = 3 eggs/day * 7 days/week\n",
      "Eggs per week = 21 eggs/week\n",
      "\n",
      "Step 2: Determine the total number of eggs in 4 weeks.\n",
      "Now that we know Claire eats 21 eggs per week, we can calculate the total number of eggs she eats in 4 weeks by multiplying the number of eggs per week by the number of weeks:\n",
      "Total eggs in 4 weeks = Eggs per week * Number of weeks\n",
      "Total eggs in 4 weeks = 21 eggs/week * 4 weeks\n",
      "Total eggs in 4 weeks = 84 eggs\n",
      "\n",
      "Step 3: Determine the number of dozens of eggs.\n",
      "To determine the number of dozens of eggs, we need to convert the total number of eggs into dozens. Since 1 dozen is equal to 12 eggs, we can divide the total number of eggs by 12:\n",
      "Number of dozens of eggs = Total eggs in 4 weeks / 12 eggs/dozen\n",
      "Number of dozens of eggs = 84 eggs / 12 eggs/dozen\n",
      "Number of dozens of eggs = 7 dozens\n",
      "\n",
      "Therefore, Claire will eat 7 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 2983.0517578125MB\n"
     ]
    }
   ],
   "source": [
    "config = GenerationConfig(max_length=1024, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"], \n",
    "                          do_sample=True, temperature=0.7, top_k=None, top_p=None, min_p=0.1, \n",
    "                          return_dict_in_generate=True,\n",
    "                          eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer)\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, the age-old question of egg consumption! Let us embark on this mathematical journey together, shall we?\n",
      "\n",
      "First, we need to determine how many eggs are in one dozen. One dozen is equal to 12 eggs. So, if Claire makes 3 eggs omelets every day, in 4 weeks, we can calculate her egg consumption as follows:\n",
      "\n",
      "- There are 7 days in a week, so in 4 weeks, there are 4 x 7 = 28 days.\n",
      "- If Claire makes 3 egg omelets every day, then in 28 days, she will consume 3 x 28 = 84 eggs.\n",
      "\n",
      "Now, we need to determine how many dozens of eggs 84 is. Since 1 dozen is 12 eggs, we divide 84 by 12 to find out:\n",
      "\n",
      "- 84 eggs / 12 eggs per dozen = 7 dozen eggs\n",
      "\n",
      "Therefore, Claire will eat 7 dozen eggs in 4 weeks. This calculation demonstrates the importance of breaking down complex problems into clear steps, using fundamental mathematical principles, and acknowledging uncertainty when necessary.<|end_turn|>\n",
      "Memory usage: 330.322265625MB\n"
     ]
    }
   ],
   "source": [
    "# sampling+cache sharing+adaptive compute (maximal yapping mode ...)\n",
    "config = GenerationConfig(max_length=1024, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"], \n",
    "                          do_sample=True, temperature=0.7, top_k=None, top_p=None, min_p=0.1, \n",
    "                          return_dict_in_generate=True,\n",
    "                          eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer,\n",
    "                         criterion=\"latent-diff\", exit_threshold=0.05, cache_lookup_strategy=\"latest-m4-compress-s16\")\n",
    "print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many FLOPs? - Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use Pytorch's FLOP counter to count FLOPs, as demo'd below, but please double-check whether these measurements are correct for your `transformers` version, as the interface keeps changing. If the code below stops working, then something has changed in `transformers` that breaks the flop counter tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.flop_counter import FlopCounterMode\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated within 28.807214736938477 seconds.\n"
     ]
    }
   ],
   "source": [
    "config = GenerationConfig(max_length=1024, stop_strings=[\"<|end_text|>\", \"<|end_turn|>\"], \n",
    "                          do_sample=False, temperature=None, top_k=None, top_p=None, min_p=None, \n",
    "                          return_dict_in_generate=True,\n",
    "                          eos_token_id=65505,bos_token_id=65504,pad_token_id=65509)\n",
    "start_time = time.time()\n",
    "outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer)\n",
    "rough_demo_time_measurement = time.time() - start_time\n",
    "num_tokens = outputs.sequences.shape[1]\n",
    "print(f\"Generated within {rough_demo_time_measurement} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3703b7b99c7b4a7d9a47bec1d77d3464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module                        FLOP    % Total\n",
      "-------------------------  -------  ---------\n",
      "RavenForCausalLM           40.245T    100.00%\n",
      " - aten.mm                 39.870T     99.07%\n",
      " - aten.bmm                 0.375T      0.93%\n",
      " RavenForCausalLM.lm_head   0.254T      0.63%\n",
      "  - aten.mm                 0.254T      0.63%\n",
      "Expected TFLOPs per token: 0.11\n"
     ]
    }
   ],
   "source": [
    "with torch.device(\"meta\"):\n",
    "    meta_model = AutoModelForCausalLM.from_pretrained(\"tomg-group-umd/huginn-0125\", trust_remote_code=not USE_LOCAL_MODEL_DEFINITION, \n",
    "                                                      device_map=\"meta\", torch_dtype=torch.bfloat16)\n",
    "    x = torch.randint(0, meta_model.config.vocab_size, (1, num_tokens))\n",
    "\n",
    "\n",
    "    flop_counter = FlopCounterMode(display=True)\n",
    "    with flop_counter, torch.no_grad():\n",
    "        meta_model(input_ids=x, labels=x, num_steps=32) # measuring just inference flops\n",
    "    # with flop_counter:\n",
    "        # meta_model(input_ids=x, labels=x, num_steps=None).loss.backward() # num_steps+None measures training mean flops\n",
    "        # meta_model(input_ids=x, labels=x, num_steps=(16,4)).loss.backward() # this would measure r=16, k=4\n",
    "    measured_flops = flop_counter.get_total_flops()\n",
    "    del meta_model, x\n",
    "\n",
    "num_flop_per_token = measured_flops / num_tokens\n",
    "peak_flops = 210.6e12 # as an example for the A6000 ada, replace with your card\n",
    "print(f\"Expected TFLOPs per token: {num_flop_per_token / 1e12:4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens per second: 12.74\n",
      "MFU: 0.66%\n"
     ]
    }
   ],
   "source": [
    "tokens_per_second = num_tokens / rough_demo_time_measurement\n",
    "print(f\"Tokens per second: {tokens_per_second:4.2f}\")\n",
    "flops = num_flop_per_token * tokens_per_second\n",
    "mfu = flops / peak_flops\n",
    "print(f\"MFU: {mfu:2.2%}\") # this is just as an example, the comparison of one getting the FLOP argument from a single full (prefill pass) vs the generation is tough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Note on AMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa92883d6e1044adab4d5555116dfda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RavenForCausalLM(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(65536, 5280)\n",
       "    (prelude): ModuleList(\n",
       "      (0-1): 2 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (adapter): Linear(in_features=10560, out_features=5280, bias=False)\n",
       "    (core_block): ModuleList(\n",
       "      (0-3): 4 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (coda): ModuleList(\n",
       "      (0-1): 2 x SandwichBlock(\n",
       "        (norm_1): RMSNorm()\n",
       "        (attn): CausalSelfAttention(\n",
       "          (Wqkv): Linear(in_features=5280, out_features=15840, bias=False)\n",
       "          (proj): Linear(in_features=5280, out_features=5280, bias=False)\n",
       "        )\n",
       "        (norm_2): RMSNorm()\n",
       "        (mlp): GatedMLP(\n",
       "          (fc): Linear(in_features=5280, out_features=35840, bias=False)\n",
       "          (proj): Linear(in_features=17920, out_features=5280, bias=False)\n",
       "          (nonlin): SiLU()\n",
       "        )\n",
       "        (norm_3): RMSNorm()\n",
       "        (norm_4): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (ln_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5280, out_features=65536, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp_settings = {\"device_type\": \"cuda\", \"enabled\": True, \"dtype\": torch.bfloat16}\n",
    "if not amp_settings[\"enabled\"]:\n",
    "    torch.backends.cuda.enable_math_sdp(True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"tomg-group-umd/huginn-0125\", trust_remote_code=not USE_LOCAL_MODEL_DEFINITION)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tomg-group-umd/huginn-0125\")\n",
    "\n",
    "model.to(device=device)  # type: ignore\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>system<|end_header|>\n",
      "\n",
      "You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
      "\n",
      "Methodical reasoning, breaking complex problems into clear steps\n",
      "Mathematical and programming expertise grounded in fundamentals\n",
      "The ability to acknowledge uncertainty and correct course when needed\n",
      "Clear communication that illuminates rather than just informs\n",
      "\n",
      "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
      "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.<|end_turn|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we must first understand the number of eggs in a dozen. A dozen is 12 eggs.\n",
      "\n",
      "Now, let's calculate the number of eggs in a single omelet:\n",
      "3 eggs\n",
      "\n",
      "Next, we need to find out how many omelets Claire will make in 4 weeks. Since we don't have the exact number of days in 4 weeks, we'll assume it's approximately 30 days.\n",
      "\n",
      "Now, we can calculate the total number of eggs:\n",
      "3 eggs per omelet * 30 days = 90 eggs\n",
      "\n",
      "Finally, we can determine the number of dozens of eggs:\n",
      "90 eggs / 12 eggs per dozen = 7.5 dozens\n",
      "\n",
      "Therefore, Claire will eat approximately 7.5 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 951.8115234375MB\n"
     ]
    }
   ],
   "source": [
    "with torch.autocast(**amp_settings), torch.no_grad():\n",
    "    outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer)\n",
    "    print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_text|><|begin_header|>system<|end_header|>\n",
      "\n",
      "You are Huginn, an AI assistant who embodies careful thought and deliberation. Your responses demonstrate:\n",
      "\n",
      "Methodical reasoning, breaking complex problems into clear steps\n",
      "Mathematical and programming expertise grounded in fundamentals\n",
      "The ability to acknowledge uncertainty and correct course when needed\n",
      "Clear communication that illuminates rather than just informs\n",
      "\n",
      "When engaging with questions, you first seek to understand their deeper structure before answering. Like your namesake who flew the nine worlds seeking wisdom, you explore problems from multiple angles, helping users build genuine understanding rather than providing shallow answers.\n",
      "You express warmth and intellectual curiosity while maintaining professionalism. When faced with errors or confusion, you model honest reflection and careful correction. Your goal is not just to provide answers, but to help humans develop clearer, deeper thinking.<|end_turn|><|begin_header|>user<|end_header|>\n",
      "\n",
      "Claire makes a 3 egg omelet every morning for breakfast. How many dozens of eggs will she eat in 4 weeks?<|end_turn|><|begin_header|>Huginn<|end_header|>\n",
      "\n",
      "To determine the number of dozens of eggs Claire will eat in 4 weeks, we must first understand the number of eggs in a dozen. A dozen is 12 eggs. \n",
      "\n",
      "Now, let's calculate the total number of eggs in 4 weeks. Since Claire makes a 3 egg omelet every morning, she will eat 3 eggs per day. In 4 weeks, there are 4 x 7 = 28 days. \n",
      "\n",
      "So, the total number of eggs in 4 weeks is 3 eggs/day x 28 days = 84 eggs.\n",
      "\n",
      "Finally, we divide the total number of eggs by the number of eggs in a dozen to find out how many dozens of eggs she will eat in 4 weeks. 84 eggs / 12 eggs/dozen = 7 dozens.\n",
      "\n",
      "Therefore, Claire will eat 7 dozens of eggs in 4 weeks.<|end_turn|>\n",
      "Memory usage: 959.78759765625MB\n"
     ]
    }
   ],
   "source": [
    "with torch.autocast(**amp_settings), torch.no_grad():\n",
    "    outputs = model.generate(input_ids, config, num_steps=32, tokenizer=tokenizer, streamer=streamer)\n",
    "    print(f\"Memory usage: {outputs.past_key_values.get_memory_usage()}MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
